{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a0fbd1-53ce-4472-82d3-dc969475464e",
   "metadata": {},
   "source": [
    "# Markov Chains Rock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cdbdc-7789-4854-aaef-ffc1fc6ecb71",
   "metadata": {},
   "source": [
    "A markov chain is a blah blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8fa6d-9edd-49ad-a342-acd162818817",
   "metadata": {},
   "source": [
    "\n",
    "Markov matrices, also known as [stochastic matrices](https://en.wikipedia.org/wiki/Stochastic_matrix)\n",
    "\n",
    "It can be described by a matrix\n",
    "\n",
    "\n",
    "\n",
    "x = M x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf1da6-3d7c-4a24-ae3c-bc3c4c269439",
   "metadata": {},
   "source": [
    "In his 1948 paper, [*A mathematical theory of communication.*](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf), Claude Shannon identified a method of genering text using Markov Chains - specifically using n-grams.\n",
    "\n",
    "\n",
    "\n",
    "Here's one I made earlier. In fact, let's test it out - we shall try to generate [Moby Dick](https://www.gutenberg.org/ebooks/15) as from project Gutenberg.\n",
    "\n",
    "First I clean it up to remove copyright markings, and then train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17b7ee-4702-4bbc-b32b-5e879905b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, random, sys, textwrap, urllib\n",
    "\n",
    "N = 2 # n-gram size\n",
    "\n",
    "def circ(words, word):\n",
    "    \"\"\"pop first element and push `word` onto the end\"\"\"\n",
    "    words.pop(0)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4393446-94a7-405e-b65c-e99e715ba288",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "Get a data source. In this case, I will use Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b500ac-6c60-4437-a040-c344fce40819",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = \"https://courses.cs.washington.edu/courses/cse390c/22sp/lectures/moby.txt\"\n",
    "data = urllib.request.urlopen(target_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fdd37-e693-4ac9-8f0a-94614fafb413",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training for the Markov chain is fundamentally the following;\n",
    "Build a table of possible grams, indexed by n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa543bf-62e9-46b5-a4a0-618532cd1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = ['' for _ in range(N)]\n",
    "possibles = collections.defaultdict(list)\n",
    "for i, line in enumerate(data):\n",
    "    for word in line.split():\n",
    "        possibles[tuple(ws)].append(word)\n",
    "        circ(ws, word)\n",
    "\n",
    "# Avoid empty possibles lists at end of input\n",
    "possibles[tuple(ws)].append('')\n",
    "circ(ws,'')\n",
    "possibles[tuple(ws)].append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89c9b9-93a5-42a3-9930-52f69976bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_generate = 800\n",
    "\n",
    "# Generate randomized output (start with a random capitalized prefix)\n",
    "ws = list(random.choice([k for k in possibles if k[0][:1].isupper()]))\n",
    "output = list(ws)\n",
    "for _ in range(int(num_to_generate)):\n",
    "    word = random.choice(possibles[tuple(ws)])\n",
    "    output.append(word)\n",
    "    circ(ws, word)\n",
    "\n",
    "# Print output wrapped to 70 columns\n",
    "output = [o.decode(\"utf-8\") for o in output]\n",
    "print(textwrap.fill(' '.join(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28192a3-1771-4a80-ae7e-7f86cda5f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29a457-bb88-4812-bc94-a87a5dbf1eae",
   "metadata": {},
   "source": [
    "What about images?\n",
    "\n",
    "\n",
    "There is a way to generate images with a markov-chain like system\n",
    "\n",
    "\n",
    "[Texture Synthesis by Non-parametric Sampling (Efros and Leung, 1999)](https://people.eecs.berkeley.edu/~efros/research/EfrosLeung.html) is an interesting solution to the problem of image generation.\n",
    "\n",
    "the paper is [available here](https://people.eecs.berkeley.edu/~efros/research/NPS/efros-iccv99.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5cd30-a6df-4673-be55-4385afe10d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "ErrThreshold = 0.1\n",
    "MaxErrThreshold = 0.3\n",
    "WindowSize = 5  # Example window size, can be changed as needed\n",
    "Sigma = WindowSize / 6.4\n",
    "\n",
    "def GrowImage(SampleImage, Image, WindowSize):\n",
    "    MaxErrThreshold_local = MaxErrThreshold\n",
    "    while not np.all(Image != -1):  # Assuming unfilled pixels are marked with -1\n",
    "        progress = 0\n",
    "        PixelList = GetUnfilledNeighbors(Image)\n",
    "        for Pixel in PixelList:\n",
    "            Template = GetNeighborhoodWindow(Pixel, Image, WindowSize)\n",
    "            BestMatches = FindMatches(Template, SampleImage, WindowSize)\n",
    "            if BestMatches:\n",
    "                BestMatch = RandomPick(BestMatches)\n",
    "                if BestMatch['error'] < MaxErrThreshold_local:\n",
    "                    Image[Pixel[0], Pixel[1]] = BestMatch['value']\n",
    "                    progress = 1\n",
    "        if progress == 0:\n",
    "            MaxErrThreshold_local *= 1.1\n",
    "    return Image\n",
    "\n",
    "def GetUnfilledNeighbors(Image):\n",
    "    # Assuming unfilled pixels are marked with -1 and filled with other values\n",
    "    filled_mask = Image != -1\n",
    "    dilated_mask = binary_dilation(filled_mask)\n",
    "    border_mask = dilated_mask & ~filled_mask\n",
    "    unfilled_neighbors = np.argwhere(border_mask)\n",
    "    # Optionally, sort by the number of filled neighbors (not implemented here)\n",
    "    np.random.shuffle(unfilled_neighbors)  # Random permutation\n",
    "    return unfilled_neighbors\n",
    "\n",
    "\n",
    "def GetNeighborhoodWindow(Pixel, Image, WindowSize):\n",
    "    # Pad the image to handle edges\n",
    "    pad_width = WindowSize // 2\n",
    "    padded_image = np.pad(Image, pad_width, mode='constant', constant_values=-1)\n",
    "    # Adjust the pixel location for the padding\n",
    "    Pixel_padded = (Pixel[0] + pad_width, Pixel[1] + pad_width)\n",
    "    # Extract the window\n",
    "    window = padded_image[Pixel_padded[0]-pad_width:Pixel_padded[0]+pad_width+1, \n",
    "                          Pixel_padded[1]-pad_width:Pixel_padded[1]+pad_width+1]\n",
    "    return window\n",
    "\n",
    "\n",
    "def RandomPick(BestMatches):\n",
    "    return random.choice(BestMatches)\n",
    "\n",
    "def FindMatches(Template, SampleImage, WindowSize):\n",
    "    # Create the ValidMask\n",
    "    ValidMask = (Template != -1).astype(np.float32)\n",
    "    # Gaussian mask\n",
    "    GaussMask = Gaussian2D(WindowSize, Sigma)\n",
    "    TotWeight = np.sum(GaussMask * ValidMask)\n",
    "    \n",
    "    # Initialize SSD to a high value\n",
    "    SSD = np.full(SampleImage.shape, np.inf)\n",
    "    \n",
    "    # Iterate over SampleImage\n",
    "    for i in range(SampleImage.shape[0] - WindowSize + 1):\n",
    "        for j in range(SampleImage.shape[1] - WindowSize + 1):\n",
    "            # Extract window\n",
    "            window = SampleImage[i:i+WindowSize, j:j+WindowSize]\n",
    "            # Compute SSD\n",
    "            dist = (window - Template) ** 2\n",
    "            SSD[i,j] = np.sum(dist * ValidMask * GaussMask) / TotWeight\n",
    "    \n",
    "    # Find pixels with SSD less than the threshold\n",
    "    min_SSD = np.min(SSD[np.isfinite(SSD)])\n",
    "    threshold = min_SSD * (1 + ErrThreshold)\n",
    "    matches = np.argwhere(SSD <= threshold)\n",
    "    \n",
    "    # Construct a list of dictionaries for each match\n",
    "    BestMatches = [{'error': SSD[match[0], match[1]], 'value': SampleImage[match[0], match[1]]} for match in matches]\n",
    "    return BestMatches\n",
    "\n",
    "def Gaussian2D(WindowSize, Sigma):\n",
    "    ax = np.arange(-WindowSize // 2 + 1., WindowSize // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * Sigma**2))\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8983de21-f9a4-488d-9256-018a0762b322",
   "metadata": {},
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94d8b-1d9c-42c0-8d2f-c98ede8c63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "ErrThreshold = 0.1\n",
    "MaxErrThreshold = 0.3\n",
    "WindowSize = 5\n",
    "Sigma = WindowSize / 6.4\n",
    "\n",
    "def GrowImage(SampleImage, Image, WindowSize):\n",
    "    frame_idx = 0\n",
    "\n",
    "    MaxErrThreshold_local = MaxErrThreshold\n",
    "    while not np.all(Image != -1):  # Assuming unfilled pixels are marked with -1\n",
    "        progress = 0\n",
    "        PixelList = GetUnfilledNeighbors(Image)\n",
    "        for Pixel in PixelList:\n",
    "            Template = GetNeighborhoodWindow(Pixel, Image, WindowSize)\n",
    "            BestMatches = FindMatches(Template, SampleImage, WindowSize)\n",
    "            print(BestMatches)\n",
    "            if BestMatches:\n",
    "                BestMatch = RandomPick(BestMatches)\n",
    "                if BestMatch['error'] < MaxErrThreshold_local:\n",
    "                    Image[Pixel[0], Pixel[1]] = BestMatch['value']\n",
    "                    progress = 1\n",
    "        if progress == 0:\n",
    "            MaxErrThreshold_local *= 1.1\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    return Image\n",
    "\n",
    "def GetUnfilledNeighbors(Image):\n",
    "    filled = Image != -1\n",
    "    dilated = binary_dilation(filled)\n",
    "    edge = dilated & ~filled\n",
    "    y, x = np.where(edge)\n",
    "    return list(zip(y, x))\n",
    "\n",
    "def GetNeighborhoodWindow(Pixel, Image, WindowSize):\n",
    "    half_size = WindowSize // 2\n",
    "    padded = np.pad(Image, half_size, mode='constant', constant_values=-1)\n",
    "    y, x = Pixel\n",
    "    return padded[y:y+WindowSize, x:x+WindowSize]\n",
    "\n",
    "# I think FindMatches is broken :(\n",
    "def FindMatches(Template, SampleImage, WindowSize):\n",
    "    half_size = WindowSize // 2\n",
    "    TemplateCenterValue = Template[half_size, half_size]\n",
    "    y, x = np.where(SampleImage == TemplateCenterValue)\n",
    "    matches = [{'value': SampleImage[yy, xx], 'error': 0} for yy, xx in zip(y, x)]  # Simplified\n",
    "    return matches\n",
    "\n",
    "def RandomPick(BestMatches):\n",
    "    return random.choice(BestMatches)\n",
    "\n",
    "def Gaussian2D(WindowSize, Sigma):\n",
    "    ax = np.arange(-WindowSize // 2 + 1., WindowSize // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * Sigma**2))\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea1820-a252-4c3b-aba4-fe3812bcc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of GrowImage\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate a sample image (e.g., a simple gradient)\n",
    "SampleImage = np.linspace(0, 1, 100).reshape((10, 10))\n",
    "\n",
    "# Generate an initial image with a single seed value in the center\n",
    "Image = -np.ones_like(SampleImage)\n",
    "Image[5, 5] = SampleImage[5, 5]\n",
    "\n",
    "# Grow the image - this is the fun bit!\n",
    "GrownImage = GrowImage(SampleImage, Image, WindowSize)\n",
    "\n",
    "plt.imshow(GrownImage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
